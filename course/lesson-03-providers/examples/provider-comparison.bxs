// provider-comparison.bxs
/**
 * Provider Comparison
 * Compare responses from different AI providers
 */

println( "=== Provider Comparison ===" )
println( "Testing the same prompt across multiple providers" )
println()

prompt = "Explain what a closure is in programming in 2 sentences"

providers = [
    { name: "OpenAI GPT-3.5", provider: "openai", model: "gpt-3.5-turbo" },
    { name: "OpenAI GPT-4", provider: "openai", model: "gpt-4-turbo" },
    { name: "Claude Haiku", provider: "claude", model: "claude-3-haiku-20240307" },
    { name: "Gemini Pro", provider: "gemini", model: "gemini-pro" },
    { name: "Ollama Llama", provider: "ollama", model: "llama3.2" }
]

println( "Prompt: '#prompt#'" )
println()

providers.each( config => {
    println( "-".repeat( 70 ) )
    println( "Provider: #config.name#" )
    println( "-".repeat( 70 ) )
    
    startTime = getTickCount()
    
    try {
        answer = aiChat(
            prompt,
            { model: config.model },
            { provider: config.provider }
        )
        
        elapsed = getTickCount() - startTime
        
        println( "Response:" )
        println( answer )
        println()
        println( "‚è±Ô∏è  Time: #elapsed#ms" )
        
    } catch( any e ) {
        println( "‚ùå Error: #e.message#" )
        println( "   (Provider may not be configured)" )
    }
    
    println()
} )

println( "üí° Observations:" )
println( "- Response quality varies by model" )
println( "- Speed differs significantly" )
println( "- Ollama is instant (local)" )
println( "- Cloud providers have network latency" )
