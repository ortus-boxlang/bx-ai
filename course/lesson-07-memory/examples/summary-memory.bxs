// summary-memory.bxs
/**
 * Summary Memory Demo
 * Summarizes old messages to preserve context
 */

println( "=== Summary Memory Demo ===" )
println()

// Create summary memory
memory = aiMemory( "summary", { 
    maxMessages: 10,
    summaryModel: "gpt-3.5-turbo"
} )

memory.add( aiMessage().system( "You are a helpful tutor" ) )

println( "Memory type: Summary (preserves context through summarization)" )
println()

// Have a longer conversation
topics = [
    { q: "What is a variable?", a: "A variable is a named storage location..." },
    { q: "What is a function?", a: "A function is a reusable block of code..." },
    { q: "What is an array?", a: "An array is an ordered collection..." },
    { q: "What is a loop?", a: "A loop repeats code multiple times..." },
    { q: "What is an object?", a: "An object groups data and behavior..." }
]

topics.each( ( topic, index ) => {
    println( "Turn #index + 1#:" )
    println( "  You: #topic.q#" )
    
    memory.add( aiMessage().user( topic.q ) )
    memory.add( aiMessage().assistant( topic.a ) )
    
    println( "  AI: #topic.a.left( 50 )#..." )
    println( "  Memory: #memory.count()# messages" )
    println()
} )

// Test if AI remembers early topics
println( "Testing memory of early topics:" )
println( "You: What did we discuss first?" )

memory.add( aiMessage().user( "What did we discuss first?" ) )
response = aiChat( memory.getAll() )

println( "AI: #response#" )
println()

println( "ðŸ’¡ Summary Memory:" )
println( "- Summarizes older messages" )
println( "- Preserves important context" )
println( "- Good for: long conversations" )
println( "- Better context retention than windowed" )
